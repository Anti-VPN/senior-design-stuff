# Milestones

*Perform Analysis of Cleaned up Data Set* - testing a cleaned up data set of Amazon Commerce Reviews for proof of concept. This will text the feasibility of using n-gram text analysis and help find a classifier.   

*Finish designing the core project architecture* - the base engine of the data analysis needs to be completed first. Afterwards, specific functionality can be plugged into it.

*Natural Language Processing of raw text* - being able to take raw text and converting it into a cleaned up dataset that can be used 
authorship identification. 

*Each flag/use case* - different flags are their own ambitious projects, depending on what they are.

*Implement the service in an actual application* - it is important that our project is useful for applications, so we need to test it on one to verify that our system works in practice.

# Timeline and Task List

## Zak

1. Use gRPC to create an interfacing library in Python to communicate between the analysis server and clients. **January 2019**
2. Develop the core of the analysis server in Python. **January - March 2019**

## Mitchell

1. Find a cleaned up data set to use. **November 2018**
2. Find a classifier for the cleaned up data set and test text-analysis **January 2019**
3. Help develop the core of the analysis server in Python. **January 2019**
4. Code detection of account sharing. **February 2019**
5. Test the application with real-world data and verify that it works. **March 2019**

## Brendan

1. Find a classifier for the cleaned up data set and test text-analysis **January 2019**
2. Help develop the core of the analysis server in Python. **January 2019**
3. Code detection of mass duplicate accounts. **February 2019**
4. Code detection of ban evasion. **February 2019**
5. Create a flag for text content. **March 2019**

# Effort Matrix


| Task | Estimated Working Time in Hours | Group Members |
|-------|-------|-------|
|Use gRPC to create an interfacing library in Python to communicate between the analysis server and clients | 15 Hours | Zak|
|Develop the core of the analysis server in Python|60 Hours Total|(40 hours - Zak), (10 hours - Mitchell) , (10 hours - Brendan) |
|Find a cleaned up data set|5 hours|Mitchell|
|Code detection of account sharing.| 15 Hours | Mitchell |
|Test the application with real-world data and verify that it works.| 10 Hours | Mitchell |
|Find a classifier with the cleaned up data and test text analysis|20 hours|(10 hours - Mitchell), (10 hours - Brendan)|
| Code detection of mass duplicate accounts. | 10 Hours | Brendan|
| Code detection of ban evasion. | 10 Hours | Brendan| 
| Create a flag for text content | 10 Hours | Brendan | 

## Total
* Zak - 55 hours 

* Mitchell - 50 hours 

* Brendan - 50 hours
